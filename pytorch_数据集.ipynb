{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列举一些常见的数据加载和处理工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.utils.data.Dataset`: 数据集的抽象类，需要自定义并实现 `__len__`（数据集大小）和 `__getitem__`（按索引获取样本）。\n",
    "- `torch.utils.data.TensorDataset`: 基于张量的数据集，适合处理数据-标签对，直接支持批处理和迭代。\n",
    "- `torch.utils.data.DataLoader`: 封装 Dataset 的迭代器，提供批处理、数据打乱、多线程加载等功能，便于数据输入模型训练。\n",
    "- `torchvision.datasets.ImageFolder`: 从文件夹加载图像数据，每个子文件夹代表一个类别，适用于图像分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch内置数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **MNIST**：手写数字图像数据集，用于图像分类任务。\n",
    "- **CIFAR**：包含 10 个类别，60000 张 32x32 的彩色图像数据集，用于图像分类任务。\n",
    "- **COCO**：通用物体检测、分割、关键点检测数据集，包含超过 330k 个图像和 2.5M 个目标实例的大规模数据集。\n",
    "- **ImageNet**：包含超过 1400 万张图像，用于图像分类和物体检测等任务。\n",
    "- **STL-10**：包含 100k 张 96x96 的彩色图像数据集，用于图像分类任务。\n",
    "- **Cityscapes**：包含 5000 张精细注释的城市街道场景图像，用于语义分割任务。\n",
    "- **SQUAD**：用于机器阅读理解任务的数据集。\n",
    "\n",
    "以上数据集可以通过 `torchvision.datasets` 模块中的函数进行加载，也可以通过自定义的方式加载其他数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面详细讲解两个类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset是一个抽象类\n",
    "\n",
    "自定义数据集需要继承 `torch.utils.data.Dataset` 并重写以下两个方法：\n",
    "\n",
    "- **`__len__`**：返回数据集的大小。\n",
    "- **`__getitem__`**：按索引获取一个数据样本及其标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小： 100\n",
      "第一个样本： (tensor([-0.5490, -1.0026, -1.2437,  0.0412,  0.8429]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "# 实例\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label\n",
    "    \n",
    "# 生成实例数据\n",
    "data = torch.randn(100, 5) # 100个样本，每个样本5个特征\n",
    "# 注意这里样本标签为0和1，是因为这个区间是左闭右开的，所以取不到2\n",
    "labels = torch.randint(0, 2, (100,)) # 100个样本，每个样本的标签为0或1\n",
    "\n",
    "# 实例化数据集\n",
    "dataset = MyDataset(data, labels)\n",
    "\n",
    "# 测试数据集\n",
    "print('数据集大小：', len(dataset))\n",
    "print('第一个样本：', dataset[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataLoader** 是 PyTorch 提供的数据加载器，用于批量加载数据集。\n",
    "\n",
    "提供了以下功能：\n",
    "\n",
    "- **批量加载**：通过设置 `batch_size`。\n",
    "- **数据打乱**：通过设置 `shuffle=True`。\n",
    "- **多线程加速**：通过设置 `num_workers`。\n",
    "- **迭代访问**：方便地按批次访问数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 自定义数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        # 数据初始化\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集大小\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 按索引返回数据和标签\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label\n",
    "\n",
    "# 生成示例数据\n",
    "data = torch.randn(100, 5)  # 100 个样本，每个样本有 5 个特征\n",
    "labels = torch.randint(0, 2, (100,))  # 100 个标签，取值为 0 或 1\n",
    "\n",
    "# 实例化数据集\n",
    "dataset = MyDataset(data, labels)\n",
    "# 实例化 DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=0)\n",
    "\n",
    "# 遍历 DataLoader\n",
    "for batch_idx, (batch_data, batch_labels) in enumerate(dataloader): #enumberate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标\n",
    "    print(f\"批次 {batch_idx + 1}\")\n",
    "    print(\"数据:\", batch_data)\n",
    "    print(\"标签:\", batch_labels)\n",
    "    if batch_idx == 2:  # 仅显示前 3 个批次\n",
    "        break\n",
    "\n",
    "\n",
    "# 自己的理解：先生成一批样本data，这批样本有100个，每个样本有5个特征\n",
    "# 然后生成这批样本的标签，100个样本的标签为0或1\n",
    "# 然后实例化数据集，是自定义的一个类MyDataset，这个类继承了torch.utils.data.Dataset\n",
    "# 然后通过MyDataset类实例化一个数据集dataset，也就是将data和labels传入MyDataset类中，放到dataset中\n",
    "# 然后实例化DataLoader, 也就是将dataset传入DataLoader中，并设置batch_size=10, shuffle=True, num_workers=0这几个参数\n",
    "# 然后遍历DataLoader，通过enumerate()函数将DataLoader中的数据和数据下标组合成一个索引序列，然后遍历这个索引序列\n",
    "# 在遍历的过程中，将每个批次的数据和标签打印出来，当遍历到第3个批次的时候，就退出遍历\n",
    "# 这样就完成了一个简单的数据集的生成和遍历的过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下将一个CSV文件作为数据源，然后通过自定义的Dataset和DateLoader读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./img/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征: tensor([[ 1.2000,  2.1000, -3.0000],\n",
      "        [ 1.5000,  2.2000, -1.1000],\n",
      "        [-1.1000,  0.8000,  1.5000],\n",
      "        [ 1.0000,  1.1000, -2.0000],\n",
      "        [-0.3000,  0.8000,  1.2000]])\n",
      "标签: tensor([1., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 自定义 CSV 数据集，类似于上面的 MyDataset\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        # 读取 CSV 文件\n",
    "        self.data = pd.read_csv(file_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集大小\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 使用 .iloc 明确基于位置索引\n",
    "        row = self.data.iloc[idx]\n",
    "        # 将特征和标签分开\n",
    "        features = torch.tensor(row.iloc[:-1].to_numpy(), dtype=torch.float32)  # 特征\n",
    "        label = torch.tensor(row.iloc[-1], dtype=torch.float32)  # 标签\n",
    "        return features, label\n",
    "\n",
    "# 实例化数据集和 DataLoader\n",
    "dataset = CSVDataset(\"runoob_pytorch_data.csv\")\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# 遍历 DataLoader\n",
    "for features, label in dataloader:\n",
    "    print(\"特征:\", features)\n",
    "    print(\"标签:\", label)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
